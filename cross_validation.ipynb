{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts that construct a splited dataset for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#Set seed\n",
    "random.seed(10)\n",
    "\n",
    "#Import dataset\n",
    "dataset = pd.read_csv('dataset/dataframe_after_exploratory_analysis_and_cleaning_data_1.csv',index_col = 0, sep = ';')\n",
    "\n",
    "#Cross Validation\n",
    "\n",
    "#Separe the test dataset\n",
    "auxiliar_test = dataset.loc[dataset.year.isin([2016,2017])]\n",
    "dataset_without_2016_2017 = dataset.loc[~dataset.year.isin([2016,2017])]\n",
    "temporary = auxiliar_test.loc[auxiliar_test.product_type == 'temporary']\n",
    "permanent = auxiliar_test.loc[auxiliar_test.product_type == 'permanent']\n",
    "pasture = auxiliar_test.loc[auxiliar_test.product_type == 'pasture']\n",
    "\n",
    "#Temporary test\n",
    "temporary_without_test_cases = pd.DataFrame([], columns = ['destinated_area', 'city_code', 'product', 'product_type','year'])\n",
    "temporary_test_cases = pd.DataFrame([], columns = ['destinated_area', 'city_code', 'product', 'product_type','year'])\n",
    "for year,sub_df in temporary.groupby('year'):\n",
    "    position = random.sample([i for i in range(len(sub_df))],int(len(sub_df)*(0.05)))\n",
    "    temporary_without_test_cases = pd.concat([temporary_without_test_cases,sub_df.iloc[list(set(range(len(sub_df)))-set(position)),:]])\n",
    "    temporary_test_cases = pd.concat([temporary_test_cases,sub_df.iloc[position,:]])\n",
    "\n",
    "#Permanent test\n",
    "permanent_without_test_cases = pd.DataFrame([], columns = ['destinated_area', 'city_code', 'product', 'product_type','year'])\n",
    "permanent_test_cases = pd.DataFrame([], columns = ['destinated_area', 'city_code', 'product', 'product_type','year'])\n",
    "for year,sub_df in permanent.groupby('year'):\n",
    "    position = random.sample([i for i in range(len(sub_df))],int(len(sub_df)*(0.05)))\n",
    "    permanent_without_test_cases = pd.concat([permanent_without_test_cases,sub_df.iloc[list(set(range(len(sub_df)))-set(position)),:]])\n",
    "    permanent_test_cases = pd.concat([permanent_test_cases,sub_df.iloc[position,:]])\n",
    "\n",
    "#Pasture test\n",
    "pasture_without_test_cases = pd.DataFrame([], columns = ['destinated_area', 'city_code', 'product', 'product_type','year'])\n",
    "pasture_test_cases = pd.DataFrame([], columns = ['destinated_area', 'city_code', 'product', 'product_type','year'])\n",
    "for year,sub_df in pasture.groupby('year'):\n",
    "    position = random.sample([i for i in range(len(sub_df))],int(len(sub_df)*(0.05)))\n",
    "    pasture_without_test_cases = pd.concat([pasture_without_test_cases,sub_df.iloc[list(set(range(len(sub_df)))-set(position)),:]])\n",
    "    pasture_test_cases = pd.concat([pasture_test_cases,sub_df.iloc[position,:]])\n",
    "\n",
    "test = pd.concat([temporary_test_cases,permanent_test_cases,pasture_test_cases])\n",
    "dataset = pd.concat([temporary_without_test_cases,permanent_without_test_cases,pasture_without_test_cases,dataset_without_2016_2017])\n",
    "\n",
    "#Split dataset into 10 sub_dataset\n",
    "temporary = dataset.loc[dataset.product_type == 'temporary']\n",
    "permanent = dataset.loc[dataset.product_type == 'permanent']\n",
    "pasture = dataset.loc[dataset.product_type == 'pasture']\n",
    "size = int(len(dataset)*0.1)\n",
    "df = []\n",
    "for _ in range(10):\n",
    "    df.append(pd.DataFrame([], columns = ['destinated_area', 'city_code', 'product', 'product_type','year']))\n",
    "for product_type,sub_df_1 in dataset.groupby('product_type'):\n",
    "    for year,sub_df_2 in sub_df_1.groupby('year'):\n",
    "        positions_splited = []\n",
    "        all_positions = [i for i in range(len(sub_df_2))]\n",
    "        chosen_positions = set()\n",
    "        for _ in range(9):\n",
    "            aux = random.sample(list(set(all_positions)-chosen_positions),int(len(sub_df_2)*0.10))\n",
    "            positions_splited.append(aux)\n",
    "            chosen_positions = chosen_positions.union(aux)\n",
    "        positions_splited.append(list(set(all_positions)-chosen_positions))\n",
    "        for i in range(10):\n",
    "            df[i] = pd.concat([df[i],sub_df_2.iloc[positions_splited[i],:]])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#Set seed\n",
    "random.seed(10)\n",
    "\n",
    "#Import dataset\n",
    "timeseries = pd.read_csv('dataset/time_series_after_exploratory_analysis_and_cleaning_data_1.csv',index_col = 0, sep = ';')\n",
    "\n",
    "#Cross Validation for time series\n",
    "\n",
    "#Separe the test dataset\n",
    "temporary = timeseries.loc[timeseries.product_type == 'temporary']\n",
    "permanent = timeseries.loc[timeseries.product_type == 'permanent']\n",
    "pasture = timeseries.loc[timeseries.product_type == 'pasture']\n",
    "\n",
    "#Temporary test\n",
    "position = random.sample([i for i in range(len(temporary))],int(len(temporary)*(0.05)))\n",
    "temporary_without_test_cases = temporary.iloc[list(set(range(len(temporary)))-set(position)),:]\n",
    "temporary_test_cases = temporary.iloc[position,:]\n",
    "\n",
    "#Permanent test\n",
    "position = random.sample([i for i in range(len(permanent))],int(len(permanent)*(0.05)))\n",
    "permanent_without_test_cases = permanent.iloc[list(set(range(len(permanent)))-set(position)),:]\n",
    "permanent_test_cases = permanent.iloc[position,:]\n",
    "\n",
    "#Pasture test\n",
    "position = random.sample([i for i in range(len(pasture))],int(len(pasture)*(0.05)))\n",
    "pasture_without_test_cases = pasture.iloc[list(set(range(len(pasture)))-set(position)),:]\n",
    "pasture_test_cases = pasture.iloc[position,:]\n",
    "\n",
    "test = pd.concat([temporary_test_cases,permanent_test_cases,pasture_test_cases])\n",
    "timeseries = pd.concat([temporary_without_test_cases,permanent_without_test_cases,pasture_without_test_cases])\n",
    "\n",
    "#Split the dataset into 10\n",
    "temporary = timeseries.loc[timeseries.product_type == 'temporary']\n",
    "permanent = timeseries.loc[timeseries.product_type == 'permanent']\n",
    "pasture = timeseries.loc[timeseries.product_type == 'pasture']\n",
    "size = int(len(timeseries)*0.1)\n",
    "df = []\n",
    "for _ in range(10):\n",
    "    df.append(pd.DataFrame([], columns = timeseries.columns))\n",
    "for product_type,sub_df in timeseries.groupby('product_type'):\n",
    "    positions_splited = []\n",
    "    all_positions = [i for i in range(len(sub_df))]\n",
    "    chosen_positions = set()\n",
    "    for _ in range(9):\n",
    "        aux = random.sample(list(set(all_positions)-chosen_positions),int(len(sub_df)*0.10))\n",
    "        positions_splited.append(aux)\n",
    "        chosen_positions = chosen_positions.union(aux)\n",
    "    positions_splited.append(list(set(all_positions)-chosen_positions))\n",
    "    for i in range(10):\n",
    "        df[i] = pd.concat([df[i],sub_df.iloc[positions_splited[i],:]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd3106f17cb3399392c4dccb9a8c82bd3788e8313257aff6101ca648ee8f14a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
